# Automatic-presentation-evaluation

A student-friendly Python project that evaluates presentations in real-time using audio-visual analysis. It provides immediate feedback on speaking pace, eye contact, facial emotion, and vocal clarity using advanced AI and computer vision tools.

## ğŸš€ Features

- ğŸ¤ Real-time speech analysis (clarity, speed, pitch)
- ğŸ‘€ Eye contact detection using MediaPipe & OpenCV
- ğŸ˜Š Facial expression analysis with DeepFace
- ğŸ“Š Feedback charts using Matplotlib
- ğŸ”„ Immediate results & evaluation summary
- ğŸ§‘â€ğŸ“ Designed for students & training sessions

## ğŸ§ª Technologies Used

- Python 3.x
- OpenCV
- MediaPipe (Face & Eye tracking)
- Praat-Parselmouth (voice analysis)
- DeepFace (emotion recognition)
- NumPy & Matplotlib (data & visuals)


## âš™ï¸ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/Subhajitindia99das/Automatic-presentation-evaluation.git
   cd auto-presentation-eval


